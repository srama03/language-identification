{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9g_h3aSbufkO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Setting up the environment\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KiqlnaZ6vDjC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14EPx2hSucvh",
        "outputId": "f97b1a66-69dd-4374-d7f8-d41b8feecf39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collecting and Processing data"
      ],
      "metadata": {
        "id": "JMcAMaktvQma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import fasttext\n",
        "import re"
      ],
      "metadata": {
        "id": "zdGq2w0N45lF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download and extract Tatoeba dataset\n",
        "!wget https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
        "!tar -xvjf sentences.tar.bz2\n",
        "#load dataset\n",
        "df= pd.read_csv(\"sentences.csv\", sep=\"\\t\", names=['SentenceID', \"Language\", \"Text\"])\n",
        "#filter for top ten most common languages globally\n",
        "eight_lang = [\"eng\", \"spa\", \"ita\", \"ara\", \"epo\", \"por\", \"rus\", \"deu\"]\n",
        "filtered_df=df[df[\"Language\"].isin(eight_lang)]\n",
        "#set a limit for the number of sentences per language\n",
        "max_sentences=20000\n",
        "balanced_df=filtered_df.groupby(\"Language\", group_keys=False).apply(lambda x: x.sample(n=min(len(x), max_sentences), random_state=42)).reset_index(drop=True)\n",
        "balanced_df[\"Text\"]= balanced_df[\"Text\"].str.lower()\n",
        "#remove all punctuation except ¿ and ¡ (for spanish)\n",
        "balanced_df[\"Text\"]=balanced_df[\"Text\"].apply(lambda x: re.sub(r\"[^\\w\\s¿¡]\", \"\", x))\n",
        "#normalize whitespace\n",
        "balanced_df[\"Text\"]= balanced_df[\"Text\"].str.replace(\"\\s+\", \" \", regex=True).str.strip()\n",
        "#split into training and testing data (80-20 ratio)\n",
        "train_df=balanced_df.sample(frac=0.8, random_state=42)\n",
        "test_df=balanced_df.drop(train_df.index)\n",
        "#format for fasttext: __label__en Hello!\n",
        "train_df[\"fasttext_format\"]= \"__label__\"+train_df[\"Language\"]+\" \"+train_df[\"Text\"]\n",
        "test_df[\"fasttext_format\"]= \"__label__\"+test_df[\"Language\"]+\" \"+test_df[\"Text\"]\n",
        "#save as txt files\n",
        "train_df[\"fasttext_format\"].to_csv(\"train.txt\", index=False, header=False)\n",
        "test_df[\"fasttext_format\"].to_csv(\"test.txt\", index=False, header=False)\n",
        "print(\"data prepared\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b3q5YmmveMR",
        "outputId": "a35ad422-6da2-4249-b186-0a17f804c001"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-26 22:12:01--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199708539 (190M) [application/octet-stream]\n",
            "Saving to: ‘sentences.tar.bz2.4’\n",
            "\n",
            "sentences.tar.bz2.4 100%[===================>] 190.46M  26.7MB/s    in 8.0s    \n",
            "\n",
            "2025-01-26 22:12:10 (23.8 MB/s) - ‘sentences.tar.bz2.4’ saved [199708539/199708539]\n",
            "\n",
            "sentences.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-2535934d6327>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  balanced_df=filtered_df.groupby(\"Language\", group_keys=False).apply(lambda x: x.sample(n=min(len(x), max_sentences), random_state=42)).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(balanced_df[\"Language\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrj6d6DW7Mlr",
        "outputId": "5b4a63b5-5bca-4054-e851-50216f9138d9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language\n",
            "ara    20000\n",
            "deu    20000\n",
            "eng    20000\n",
            "epo    20000\n",
            "ita    20000\n",
            "por    20000\n",
            "rus    20000\n",
            "spa    20000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the Model"
      ],
      "metadata": {
        "id": "fa4QgwgP5B_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=fasttext.train_supervised(\n",
        "    input=\"train.txt\",\n",
        "    lr=0.05,\n",
        "    epoch=70,\n",
        "    wordNgrams=4,\n",
        "    dim=100,\n",
        "    bucket=100000\n",
        "    )\n",
        "#save the model\n",
        "model.save_model(\"language_identifier.bin\")\n",
        "print(\"model trained and saved!\")"
      ],
      "metadata": {
        "id": "h-V3xaLZ5IKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d09d22-d182-46a1-ef97-5fc583913be7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model trained and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Model"
      ],
      "metadata": {
        "id": "jveudVXWebJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in eight_lang:\n",
        "  lang_test_df= test_df[test_df[\"Language\"]==lang]\n",
        "  lang_test_file= f\"test_{lang}.txt\"\n",
        "  lang_test_df[\"fasttext_format\"].to_csv(lang_test_file, index=False, header=False)\n",
        "  result = model.test(lang_test_file)\n",
        "  print(f\"Language: {lang}\")\n",
        "  print(f\"  Number of samples: {result[0]}\")\n",
        "  print(f\"  Precision: {result[1]:.2f}\")\n",
        "  print(f\"  Recall: {result[2]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg7R9eG5ogqQ",
        "outputId": "20b5eb08-fc31-42cd-dc9f-e1881127b28f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language: eng\n",
            "  Number of samples: 3939\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "Language: spa\n",
            "  Number of samples: 4039\n",
            "  Precision: 0.96\n",
            "  Recall: 0.96\n",
            "Language: ita\n",
            "  Number of samples: 4036\n",
            "  Precision: 0.98\n",
            "  Recall: 0.98\n",
            "Language: ara\n",
            "  Number of samples: 4123\n",
            "  Precision: 1.00\n",
            "  Recall: 1.00\n",
            "Language: epo\n",
            "  Number of samples: 3940\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n",
            "Language: por\n",
            "  Number of samples: 4014\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "Language: rus\n",
            "  Number of samples: 3957\n",
            "  Precision: 0.97\n",
            "  Recall: 0.97\n",
            "Language: deu\n",
            "  Number of samples: 3952\n",
            "  Precision: 0.99\n",
            "  Recall: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result= model.test(\"test.txt\")\n",
        "print(f\"Number of test samples: {result[0]}\")\n",
        "print(f\"Precision: {result[1]:.2f}\")\n",
        "print(f\"Recall: {result[2]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaaN4hM4enk_",
        "outputId": "deb6c527-a76c-4cc7-8fa2-c89cac6c2b4a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples: 32000\n",
            "Precision: 0.98\n",
            "Recall: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"Hello, how are you?\",  # English\n",
        "    \"Hola, ¿cómo estás?\",   # Spanish\n",
        "    \"السلام عليكم\",          # Arabic\n",
        "    \"Olá, como vai você?\",   # Portuguese\n",
        "    \"Привет, как дела?\",     # Russian\n",
        "    \"Wie geht es dir?\",       # German\n",
        "    \"Ciao, come stai?\",       # Italian\n",
        "    \"Saluton, kiel vi fartas?\" # Esperanto\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    predictions = model.predict(sentence, k=1)  # Get top 3 predictions\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predictions: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAkamcjj9M_Z",
        "outputId": "50b3f7a4-8762-4238-e520-61fa1ab060a1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Hello, how are you?\n",
            "Predictions: (('__label__eng',), array([0.99995065]))\n",
            "Sentence: Hola, ¿cómo estás?\n",
            "Predictions: (('__label__spa',), array([0.99940026]))\n",
            "Sentence: السلام عليكم\n",
            "Predictions: (('__label__ara',), array([0.99407828]))\n",
            "Sentence: Olá, como vai você?\n",
            "Predictions: (('__label__por',), array([0.99355209]))\n",
            "Sentence: Привет, как дела?\n",
            "Predictions: (('__label__rus',), array([0.99981493]))\n",
            "Sentence: Wie geht es dir?\n",
            "Predictions: (('__label__deu',), array([0.85577619]))\n",
            "Sentence: Ciao, come stai?\n",
            "Predictions: (('__label__ita',), array([0.96978873]))\n",
            "Sentence: Saluton, kiel vi fartas?\n",
            "Predictions: (('__label__epo',), array([1.00000942]))\n"
          ]
        }
      ]
    }
  ]
}
